maxc <- filter(gathered_measurements, bin<=24, sec>=3300, sec<=3420) %>%
group_by(bin) %>%
summarise(maxc=mean(measurement)) %>%
left_join(bin_info, by="bin") %>%
as.data.frame()
ggplot(maxc, aes(mid, maxc))+geom_point()
maxc <- filter(gathered_measurements, bin<=24, sec>=3300, sec<=3420) %>%
group_by(bin) %>%
summarise(maxc=mean(measurement)) %>%
left_join(bin_info, by="bin") %>%
as.data.frame()
ggplot(maxc, aes(mid, maxc))+geom_point()
maxc
sum(maxc$maxc)
ggplot(maxc, aes(mid, maxc))+geom_point()+coord_trans(x="log10", y="log10")
ggplot(maxc, aes(mid, maxc))+geom_point()+coord_trans(x="log10")
ggplot(maxc[-c(1:3, 7, 10),], aes(mid, maxc))+geom_point()+coord_trans(x="log10")
ggplot(maxc[-c(1:3, 7, 10),], aes(mid, maxc))+geom_point()+coord_trans(x="log10")+geom_smooth(method = "loess")
?geom_smooth
ggplot(maxc[-c(1:3, 7, 10),], aes(mid, maxc))+geom_point()+coord_trans(x="log10")
?smooth.spline
maxc_log <- maxc[-c(1:3, 7, 10),] %>%
mutate(mid_log=log10(mid))
ss <- smooth.spline(x=as.matrix(select(mid_log, mid_log, maxc)), lambda=0.1)
ss <- smooth.spline(x=as.matrix(select(maxc_log, mid_log, maxc)), lambda=0.1)
plot(ss)
plot(ss)
points(maxc~mid_log, data=maxc_log, col="red")
ss <- smooth.spline(x=as.matrix(select(maxc_log, mid_log, maxc)), lambda=0.00001)
plot(ss)
points(maxc~mid_log, data=maxc_log, col="red")
ss <- smooth.spline(x=as.matrix(select(maxc_log, mid_log, maxc)), lambda=0.0000001)
plot(ss)
points(maxc~mid_log, data=maxc_log, col="red")
ss <- smooth.spline(x=as.matrix(select(maxc_log, mid_log, maxc)), lambda=0.0001)
plot(ss)
points(maxc~mid_log, data=maxc_log, col="red")
predict(ss, 7)
ss <- smooth.spline(x=as.matrix(select(maxc_log, mid_log, maxc)), lambda=0.0001)
plot_ss <- function(x) predict(ss, x)$y
curve(plot_ss, from=min(maxc$lower), to=max(maxc$upper))
points(maxc~mid_log, data=maxc_log, col="red")
maxc
ss <- smooth.spline(x=as.matrix(select(maxc_log, mid_log, maxc)), lambda=0.0001)
plot_ss <- function(x) predict(ss, x)$y
curve(plot_ss, from=min(log10(maxc$lower)), to=max(log10(maxc$upper)))
points(maxc~mid_log, data=maxc_log, col="red")
ss <- smooth.spline(x=as.matrix(select(maxc_log, mid_log, maxc)), lambda=0.001)
plot_ss <- function(x) predict(ss, x)$y
curve(plot_ss, from=min(log10(maxc$lower)), to=max(log10(maxc$upper)))
points(maxc~mid_log, data=maxc_log, col="red")
ss <- smooth.spline(x=as.matrix(select(maxc_log, mid_log, maxc)), lambda=0.0001)
plot_ss <- function(x) predict(ss, x)$y
curve(plot_ss, from=min(log10(maxc$lower)), to=max(log10(maxc$upper)))
points(maxc~mid_log, data=maxc_log, col="red")
ss <- smooth.spline(x=as.matrix(select(maxc_log, mid_log, maxc)), lambda=0.0001)
plot_ss <- function(x) predict(ss, x)$y
points(maxc~mid_log, data=maxc_log, col="red")
curve(plot_ss, from=min(log10(maxc$lower)), to=max(log10(maxc$upper)))
ss <- smooth.spline(x=as.matrix(select(maxc_log, mid_log, maxc)), lambda=0.0001)
plot_ss <- function(x) predict(ss, x)$y
points(maxc~mid_log, data=maxc_log, col="red")
curve(plot_ss, from=min(log10(maxc$lower)), to=max(log10(maxc$upper)), add=TRUE)
ss <- smooth.spline(x=as.matrix(select(maxc_log, mid_log, maxc)), lambda=0.00001)
plot_ss <- function(x) predict(ss, x)$y
points(maxc~mid_log, data=maxc_log, col="red")
curve(plot_ss, from=min(log10(maxc$lower)), to=max(log10(maxc$upper)), add=TRUE)
ss <- smooth.spline(x=as.matrix(select(maxc_log, mid_log, maxc)), lambda=0.00001)
plot_ss <- function(x) predict(ss, x)$y
plot(maxc~mid_log, data=maxc_log, col="red")
curve(plot_ss, from=min(log10(maxc$lower)), to=max(log10(maxc$upper)), add=TRUE)
ss <- smooth.spline(x=as.matrix(select(maxc_log, mid_log, maxc)), lambda=0.0001)
plot_ss <- function(x) predict(ss, x)$y
plot(maxc~mid_log, data=maxc_log, col="red")
curve(plot_ss, from=min(log10(maxc$lower)), to=max(log10(maxc$upper)), add=TRUE)
maxc_log
maxc
maxc <- maxc %>%
mutate(predc=plot_ss(mid))
maxc
axc <- maxc %>%
mutate(predc=plot_ss(log10(mid)))
rm(axc)
maxc <- maxc %>%
mutate(predc=plot_ss(log10(mid)))
maxc
maxc <- maxc %>%
mutate(predc=plot_ss(log10(mid))) %>%
mutate(predc=ifelse(predc<0, 0, predc))
,axc
maxc
sum(maxc$predc)
log(165)
log10(165)
?abline
ss <- smooth.spline(x=as.matrix(select(maxc_log, mid_log, maxc)), lambda=0.0001)
plot_ss <- function(x) predict(ss, x)$y
plot(maxc~mid_log, data=maxc_log, col="red")
curve(plot_ss, from=min(log10(maxc$lower)), to=max(log10(maxc$upper)), add=TRUE)
abline(v=log10(165))
dev.new()
library(dplyr)
library(magrittr)
library(ggplot2)
file <- "C:\\Users\\Bearkey\\Documents\\Ecogeomorphic_Flume\\esdlflume\\data\\raw\\Flume -- LISST -- Sept 2018-\\20181115\\11_15_particle_size_dist.asc"
correction <- TRUE #set this to TRUE if you want to remove all data points that have a transmission outside of the optimal range of 0.1 to 0.995
time_start <- 2200 #set start time for the data analysis to exclude initialization
time_end <- Inf #set end time for data analysis
###Data Processing Section###
bins <- 1:32
raw <- read.table(file, header=FALSE) #%>% mutate(V41=V41/100) #reading the .asc file as a table
laser_reference <- any(raw[,36]==0) #laser reference values should all be much greater than 0
if (laser_reference==TRUE) {
warning("Laser reference has a 0 value")
}
transmission <- any(c(raw[,41]<=0, raw[,41]>=1)) #it is physically impossible to have a transmission not in the range 0 to 1
if (transmission==TRUE) {
warning("Transmission has value(s) outside of the range 0 to 1")
}
if (correction==TRUE) {
raw <- raw %>%
filter(V36>0, V41>=0.1, V41<=0.995)
}
time_converted_sec <- raw %>%
mutate(min=as.numeric(ifelse(V40>=100, gsub("[[:digit:]]{2}$", "", V40), 0))) %>%
mutate(sec=as.numeric(ifelse(V40>=1000, gsub("^[[:digit:]]{2}", "", V40), ifelse(V40<1000 & V40>=100, gsub("^[[:digit:]]", "", V40), V40)))) %>%
mutate(sec=sec+(min*60)) %>%
select(-min) #conversion of time units to seconds
diff <- c(0, diff(time_converted_sec[,"sec"]))
diff[diff<0] <- diff[diff<0]+3600
seconds <- cumsum(diff)+1
time_converted_final <- time_converted_sec %>%
mutate(sec=seconds) #setting seconds to start at 0 and count increasing (as opposed to cyclically)
gathered_measurements <- time_converted_final %>%
tidyr::gather(key=bin, value=measurement, 1:32) %>%
mutate(bin=as.numeric(gsub("^V", "", bin))) %>%
select(sec, bin, measurement) %>% #combining particle concentration data into a single field
filter(sec>=time_start, sec<=time_end)
bin_plotter <- function(bin_k) {
selected_bin <- filter(gathered_measurements, bin==bin_k)
plot <- ggplot(selected_bin, aes(x=sec, y=measurement))+geom_point(size=0.2)+theme(axis.title=element_blank())
return(plot)
}
plot_list <- lapply(bins, bin_plotter)
#dev.new()
cowplot::plot_grid(plotlist=plot_list, nrow=4, ncol=8)
maxc_log
log10(0)
log10(-0.33)
log10(0.33)
maxc
#01 Parametric (Normal Distribution) Particle Size Estimation from Sieve Analysis
#This script fits a normal distribution CDF to sieve analysis data. In effect, it is a parametric estimate of particle size distribution.
library(magrittr)
library(dplyr)
#Input (information from Composition Materials Sieve Analysis)
size <- data.frame(microns=c(420, 297, 250, 74), passing=c(1, 0.985, 0.95, 0.04)) #for 60/200 walnut shell
#size <- data.frame(microns=c(595, 420, 149, 74), passing=c(1, 0.975, 0.06, 0.0075)) #for 40/100 walnut shell
#Setup
size <- rbind(size, c(0, 0))
x <- size$microns #assigning the columns of size to individual vectors
y <- size$passing
loss <- function(par, x) sum((pnorm(x, par[1], par[2])-y)^2) #defining a quadratic loss function
#Estimate some guesses
param_est <- function(pair_df) { #a function to estimate mean and standard deviation of normal distn given two points on the CDF
pair <- pair_df$microns
prob <- pair_df$passing
sigma <- diff(pair)/diff(qnorm(prob))
mu <- pair[1]-qnorm(prob[1])*sigma
return(c(mu, sigma))
}
size_trunc <- filter(size, !(passing %in% c(0, 1))) #removing the 0 and 1 probability points because they are not well-defined
uniq <- combn(nrow(size_trunc), 2, simplify=FALSE) #all unique combinations of rows from edited data frame
estimates <- data.frame() #initializing a data frame to store parameter estimates for each pair
for (i in 1:length(uniq)) { #for loop to compute parameter estimates
estimates <- size_trunc[uniq[[i]],] %>%
param_est() %>%
rbind(estimates)
}
names(estimates) <- c("mu", "sigma") #renaming columns with better names
parameters <- optim(mapply(median, estimates), loss, lower=floor(mapply(min, estimates)), upper=ceiling(mapply(max, estimates)), method="L-BFGS-B", x=x)$par
#optimize by minimizing the RSS using the initial values and bounds from the rough estimates
#Plot the CDF
plot_func <- function(x) pnorm(x, mean=parameters[1], sd=parameters[2]) #a function to plot the CDF
curve(plot_func, from=0, to=max(x), xlab=expression(Particle~diameter~(mu~m)), ylab="Probability") #plotting the analytical CDF
abline(h=c(0, 0.5, 0.84, 1), lty=2) #plotting horizontal lines marking 0, D50 (median), D84, and 1
points(size, col="red", cex=2) #plotting the sieve analysis data
#Plot the PDF
pdf_func <- function(x) dnorm(x, mean=parameters[1], sd=parameters[2]) #a function to plot the PDF
curve(pdf_func, from=0, to=max(x), xlab=expression(Particle~diameter~(mu~m)), ylab="Density") #plotting the analytical PDF
abline(v=parameters[1], col="red", lty=2) #plotting a vertical line for the mean
abline(h=0, v=0, col="gray") #plotting gray lines for the axes
abline(v=c(abs(diff(parameters)), sum(parameters)), col="blue", lty=2) #plotting the intervals within one standard deviation
abline(v=c(parameters[1]-2*parameters[2], parameters[1]+2*parameters[2]), col="purple", lty=2) #plotting the intervals within two standard deviations
text(x=parameters[1], y=pdf_func(parameters[1]), labels=paste0("Mean = ", round(parameters[1], 4)), pos=4) #plotting label for the mean
rss <- sum((y-plot_func(x))^2) #computing the residual sum of squares
tss <- sum((y-mean(y))^2) #computing the total sum of squares
rsq <- 1-(rss/tss) #computing the coeffcient of determination to assess model fit
parameters
maxc
pnorm(12.32, mean=parameters[1], sd=parameters[2])
pnorm(12.32, mean=parameters[1], sd=parameters[2])*200
pnorm(12.32, mean=parameters[1], sd=parameters[2])*200k
k
length(k)
maxc <- maxc %>%
mutate(predc=plot_ss(log10(mid))) %>%
mutate(predc=ifelse(predc<0, 0, predc), k=k)
maxc
maxc <- maxc %>%
mutate(predc=plot_ss(log10(mid)), k=k) %>%
mutate(predc=ifelse(predc<0, 0, predc), k=ifelse(k<0, 0, k))
maxc
ggplot(maxc, aes(log10(mid, k)))+geom_point()
ggplot(maxc, aes(mid, k))+geom_point()+coord_trans(x="log10")
test <- function(x) (0.4-x)/x
curve(test, from=0, to0.4)
curve(test, from=0, to=0.4)
?stat_function
ggplot()+stat_function(fun=test, xlim=c(0, 0.4))+coord_flip()
ggplot()+stat_function(fun=test, xlim=c(0, 0.4))+coord_flip()
ggplot()+stat_function(fun=test, xlim=c(0, 0.4)
)
ggplot(data.frame(seq(0, 0.4, by=0.001)))+stat_function(fun=test)+coord_flip()
?test
ggplot(data.frame(x=seq(0, 0.4, by=0.001)))+stat_function(fun=test)+coord_flip()
?stat_function
ggplot(data.frame(x=seq(0, 0.4, by=0.001)))+stat_function(fun=test(x))+coord_flip()
test
ggplot(data.frame(x=seq(0, 0.4, by=0.001)))+stat_function(fun=function(x) (0.4-x)/x)+coord_flip()
ggplot(data=data.frame(x=seq(0, 0.4, by=0.001)))+stat_function(fun=function(x) (0.4-x)/x)+coord_flip()
ggplot(data=data.frame(x=seq(0, 0.4, by=0.001)))+stat_function(fun=test, aes(x=x))+coord_flip()
ggplot(data=data.frame(x=seq(0, 0.4, by=0.001)))+stat_function(fun=function(x) ((0.4-x)/x)^3, aes(x=x))+coord_flip()
ggplot(data=data.frame(x=seq(0, 0.4, by=0.001)))+stat_function(fun=function(x) ((0.4-x)/x)^0.25, aes(x=x))+coord_flip()
ggplot(data=data.frame(x=seq(0, 0.4, by=0.001)))+stat_function(fun=function(x) -((0.4-x)/x)^0.25, aes(x=x))+coord_flip()
ggplot(data=data.frame(x=seq(0, 0.4, by=0.001)))+stat_function(fun=function(x) -((0.4-x)/x)^1, aes(x=x))+coord_flip()
ggplot(data=data.frame(x=seq(0, 0.4, by=0.001)))+stat_function(fun=function(x) -((0.4-x)/x)^2, aes(x=x))+coord_flip()
ggplot(data=data.frame(x=seq(0, 0.4, by=0.001)))+stat_function(fun=function(x) -((0.4-x)/x)^100, aes(x=x))+coord_flip()
ggplot(data=data.frame(x=seq(0, 0.4, by=0.001)))+stat_function(fun=function(x) -((0.4-x)/x)^20, aes(x=x))+coord_flip()
ggplot(data=data.frame(x=seq(0, 0.4, by=0.001)))+stat_function(fun=function(x) -((0.4-x)/x)^0.2, aes(x=x))+coord_flip()
#Run all scripts
keep <- c("parameters", "sheardata", "size_class", "concentrationdata")
setwd("C:\\Users\\Bearkey\\Documents\\honors_thesis\\code")
source("01_parametric_particle_sizes.R")
source("02_shear_velocity.R")
source("03_concentration_ts.R")
source("04_settling.R")
source("05_rouse.R")
rm(list=ls()[!(ls() %in% keep)])
size_class
library(magrittr)
library(dplyr)
loc <- "U" #location, either upstream (U) or downstream (D)
H <- 0.4
refh <- 0.05
#Rouse number computation
sv <- filter(sheardata, dowels=="F", height==0.07) #the shear velocity in m/s
if (location=="U") {
sv <- filter(sv, relative_position<0)[1,"shearv"]
} else if (location=="D") {
sv <- filter(sv, relative_position>0)[1,"shearv"]
}
rn_func <- function(ws) ws/(0.4*sv)
size_class <- size_class %>%
mutate(rn=rn_func(ws))
loc <- "U" #location, either upstream (U) or downstream (D)
H <- 0.4
refh <- 0.05
#Rouse number computation
sv <- filter(sheardata, dowels=="F", height==0.07) #the shear velocity in m/s
if (loc=="U") {
sv <- filter(sv, relative_position<0)[1,"shearv"]
} else if (loc=="D") {
sv <- filter(sv, relative_position>0)[1,"shearv"]
}
rn_func <- function(ws) ws/(0.4*sv)
size_class <- size_class %>%
mutate(rn=rn_func(ws))
size_class
ggplot(data=data.frame(x=seq(0, 0.4, by=0.001)))+stat_function(fun=function(x) -((0.4-x)/x)^(3.420335e-03), aes(x=x))+coord_flip()
1/7
ggplot(data=data.frame(x=seq(0, 0.4, by=0.001)))+stat_function(fun=function(x) -((0.4-x)/(7*x))^(3.420335e-03), aes(x=x))+coord_flip()
ggplot(data=data.frame(x=seq(0, 0.4, by=0.001)))+stat_function(fun=function(x) -((0.4-x)/(7*x))^(2.994780e-04), aes(x=x))+coord_flip()
ggplot(data=data.frame(x=seq(0, 0.4, by=0.001)))+stat_function(fun=function(x) -((0.4-x)/(7*x))^(7.253074e-03), aes(x=x))+coord_flip()
ggplot(data=data.frame(x=seq(0, 0.4, by=0.001)))+stat_function(fun=function(x) -80*((0.4-x)/(7*x))^(7.253074e-03), aes(x=x))+coord_flip()
ggplot(data=data.frame(x=seq(0, 0.4, by=0.001)))+stat_function(fun=function(x) 80*((0.4-x)/(7*x))^(7.253074e-03), aes(x=x))
ggplot(data=data.frame(x=seq(0, 0.4, by=0.001)))+stat_function(fun=function(x) 80*((0.4-x)/(7*x))^(7.253074e-06), aes(x=x))
ggplot(data=data.frame(x=seq(0, 0.4, by=0.001)))+stat_function(fun=function(x) 80*((0.4-x)/(7*x))^(7.253074e-02), aes(x=x))
2^c(2, 3)
c(2, 3)^c(2, 3)
file.choose()
dev.new9)
dev.new())
dev.new()
library(dplyr)
library(magrittr)
library(ggplot2)
file <- "C:\\Users\\Bearkey\\Documents\\Ecogeomorphic_Flume\\esdlflume\\data\\raw\\Flume -- LISST -- Sept 2018-\\20181019_size_distn.asc"
correction <- TRUE #set this to TRUE if you want to remove all data points that have a transmission outside of the optimal range of 0.1 to 0.995
time_start <- 0 #set start time for the data analysis to exclude initialization
time_end <- Inf #set end time for data analysis
###Data Processing Section###
bins <- 1:32
raw <- read.table(file, header=FALSE) #%>% mutate(V41=V41/100) #reading the .asc file as a table
laser_reference <- any(raw[,36]==0) #laser reference values should all be much greater than 0
if (laser_reference==TRUE) {
warning("Laser reference has a 0 value")
}
transmission <- any(c(raw[,41]<=0, raw[,41]>=1)) #it is physically impossible to have a transmission not in the range 0 to 1
if (transmission==TRUE) {
warning("Transmission has value(s) outside of the range 0 to 1")
}
if (correction==TRUE) {
raw <- raw %>%
filter(V36>0, V41>=0.1, V41<=0.995)
}
time_converted_sec <- raw %>%
mutate(min=as.numeric(ifelse(V40>=100, gsub("[[:digit:]]{2}$", "", V40), 0))) %>%
mutate(sec=as.numeric(ifelse(V40>=1000, gsub("^[[:digit:]]{2}", "", V40), ifelse(V40<1000 & V40>=100, gsub("^[[:digit:]]", "", V40), V40)))) %>%
mutate(sec=sec+(min*60)) %>%
select(-min) #conversion of time units to seconds
diff <- c(0, diff(time_converted_sec[,"sec"]))
diff[diff<0] <- diff[diff<0]+3600
seconds <- cumsum(diff)+1
time_converted_final <- time_converted_sec %>%
mutate(sec=seconds) #setting seconds to start at 0 and count increasing (as opposed to cyclically)
gathered_measurements <- time_converted_final %>%
tidyr::gather(key=bin, value=measurement, 1:32) %>%
mutate(bin=as.numeric(gsub("^V", "", bin))) %>%
select(sec, bin, measurement) %>% #combining particle concentration data into a single field
filter(sec>=time_start, sec<=time_end)
bin_plotter <- function(bin_k) {
selected_bin <- filter(gathered_measurements, bin==bin_k)
plot <- ggplot(selected_bin, aes(x=sec, y=measurement))+geom_point(size=0.2)+theme(axis.title=element_blank())
return(plot)
}
plot_list <- lapply(bins, bin_plotter)
#dev.new()
cowplot::plot_grid(plotlist=plot_list, nrow=4, ncol=8)
file.choose()
library(dplyr)
library(magrittr)
library(data.table)
file <- "C:\\Users\\Bearkey\\Documents\\Ecogeomorphic_Flume\\esdlflume\\data\\raw\\1115pumpdata.csv"
data <- fread(file, data.table=FALSE)
hea(data)
head(data)
tail(data)
data <- fread(file, data.table=FALSE) %>%
select(2:4, 9)
head(data)
data <- fread(file, data.table=FALSE) %>%
select(2:4, 9)
names(data) <- c("time", "location", "height", "mc")
head(data, 10)
file <- "C:\\Users\\Bearkey\\Documents\\Ecogeomorphic_Flume\\esdlflume\\data\\raw\\1115pumpdata.csv"
data <- fread(file, data.table=FALSE) %>%
select(2:4, 9)
names(data) <- c("time", "location", "height", "mc")
data <- data %>%
filter(time>=3) %>%
mutate(time=function(x) 300*(x-2))
file <- "C:\\Users\\Bearkey\\Documents\\Ecogeomorphic_Flume\\esdlflume\\data\\raw\\1115pumpdata.csv"
data <- fread(file, data.table=FALSE) %>%
select(2:4, 9)
names(data) <- c("time", "location", "height", "mc")
data <- data %>%
filter(time>=3) %>%
mutate(time=300*(time-2))
data
file <- "C:\\Users\\Bearkey\\Documents\\Ecogeomorphic_Flume\\esdlflume\\data\\raw\\1115pumpdata.csv"
data <- fread(file, data.table=FALSE) %>%
select(2:4, 9)
names(data) <- c("time", "location", "height", "mc")
data
library(dplyr)
library(magrittr)
library(data.table)
file <- "C:\\Users\\Bearkey\\Documents\\Ecogeomorphic_Flume\\esdlflume\\data\\raw\\1115pumpdata.csv"
data <- fread(file, data.table=FALSE) %>%
select(2:4, 9)
names(data) <- c("time", "location", "height", "mc")
sp <- tidyr::spread(data, key=location, value=time, height, mc)
sp <- tidyr::spread(data, key=location)
file <- "C:\\Users\\Bearkey\\Documents\\Ecogeomorphic_Flume\\esdlflume\\data\\raw\\1115pumpdata.csv"
data <- fread(file, data.table=FALSE) %>%
select(2:4, 9)
names(data) <- c("time", "location", "height", "mc")
sp <- tidyr::spread(data, key=location)
?tidyr::spread
sp <- tidyr::spread(data, key=location, value=mc)
sp
?wilcox.test
file <- "C:\\Users\\Bearkey\\Documents\\Ecogeomorphic_Flume\\esdlflume\\data\\raw\\1115pumpdata.csv"
data <- fread(file, data.table=FALSE) %>%
select(2:4, 9)
names(data) <- c("time", "location", "height", "mc")
sp <- tidyr::spread(data, key=location, value=mc) %>%
mutate(diff=U-D)
hist(sp$diff)
?Wilcoxon
?wilcox.test
mean(sp$diff)
input <- sp %>%
select(U, D) %>%
rename(U=x, D=y)
input <- sp %>%
select(U, D) %>%
rename(x=U, y=D)
input
file <- "C:\\Users\\Bearkey\\Documents\\Ecogeomorphic_Flume\\esdlflume\\data\\raw\\1115pumpdata.csv"
data <- fread(file, data.table=FALSE) %>%
select(2:4, 9)
names(data) <- c("time", "location", "height", "mc")
sp <- data %>%
filter(time>=3) %>%
tidyr::spread(key=location, value=mc) %>%
mutate(diff=U-D)
input <- sp %>%
select(U, D) %>%
rename(x=U, y=D)
input
wilcox.test(x=input, alternative="greater", paired=TRUE)
as.matrix(input)
wilcox.test(x=as.matrix(input), alternative="greater", paired=TRUE)
wilcox.test(x=input$x, y=input$y, alternative="greater", paired=TRUE)
wilcox.test(x=input$x, y=input$y, alternative="two.sided", paired=TRUE)
wilcox.test(x=input$x, y=input$y, alternative="less", paired=TRUE)
wilcox.test(x=log(input$x), y=log(input$y), alternative="greater", paired=TRUE)
?t.test
t.test(x=input$x, y=input$y, alternative="greater", paired=TRUE)
size_class
maxc
library(dplyr)
library(magrittr)
library(ggplot2)
library(data.table)
settings <- data.frame(
bins=c(1:14, 15:24),
st=c(4700, 5900),
ed=c(Inf, 7100)
)
file <- "C:\\Users\\Bearkey\\Documents\\Ecogeomorphic_Flume\\esdlflume\\data\\raw\\Flume -- LISST -- Sept 2018-\\20181115\\11_15_particle_size_dist.asc"
correction <- TRUE #set this to TRUE if you want to remove all data points that have a transmission outside of the optimal range of 0.1 to 0.995
time_start <- 0 #set start time for the data analysis to exclude initialization
time_end <- Inf #set end time for data analysis
###Data Processing Section###
bins <- 1:32
raw <- read.table(file, header=FALSE) #%>% mutate(V41=V41/100) #reading the .asc file as a table
laser_reference <- any(raw[,36]==0) #laser reference values should all be much greater than 0
if (laser_reference==TRUE) {
warning("Laser reference has a 0 value")
}
transmission <- any(c(raw[,41]<=0, raw[,41]>=1)) #it is physically impossible to have a transmission not in the range 0 to 1
if (transmission==TRUE) {
warning("Transmission has value(s) outside of the range 0 to 1")
}
if (correction==TRUE) {
raw <- raw %>%
filter(V36>0, V41>=0.1, V41<=0.995)
}
time_converted_sec <- raw %>%
mutate(min=as.numeric(ifelse(V40>=100, gsub("[[:digit:]]{2}$", "", V40), 0))) %>%
mutate(sec=as.numeric(ifelse(V40>=1000, gsub("^[[:digit:]]{2}", "", V40), ifelse(V40<1000 & V40>=100, gsub("^[[:digit:]]", "", V40), V40)))) %>%
mutate(sec=sec+(min*60)) %>%
select(-min) #conversion of time units to seconds
diff <- c(0, diff(time_converted_sec[,"sec"]))
diff[diff<0] <- diff[diff<0]+3600
seconds <- cumsum(diff)+1
time_converted_final <- time_converted_sec %>%
mutate(sec=seconds) #setting seconds to start at 0 and count increasing (as opposed to cyclically)
gathered_measurements <- time_converted_final %>%
tidyr::gather(key=bin, value=measurement, 1:32) %>%
mutate(bin=as.numeric(gsub("^V", "", bin))) %>%
select(sec, bin, measurement) %>% #combining particle concentration data into a single field
filter(sec>=time_start, sec<=time_end) %>%
mutate(logc=log(measurement))
grp1 <- gathered_measurements %>%
filter(bin<=14, sec>=4700) %>%
mutate(sec=sec-min(sec))
grp2 <- gathered_measurements %>%
filter(bin>=15, bin<=24, sec>=5900, sec<=7100) %>%
mutate(sec=sec-min(sec))
data_ed <- rbind(grp1, grp2)
k <- c()
for (i in 1:length(unique(data_ed$bin))) {
mod <- lm(logc~sec, data=filter(data_ed, bin==i))
k <- c(k, -coef(mod)[2])
}
k <- unname(k)
bin_info <- fread("C:\\Users\\Bearkey\\Documents\\Ecogeomorphic_Flume\\esdlflume\\data\\raw\\lisst bins.tsv", data.table=FALSE)[,c(1, 8:10)]
names(bin_info) <- c("bin", "lower", "upper", "mid")
maxc <- filter(gathered_measurements, bin<=24, sec>=3300, sec<=3420) %>%
group_by(bin) %>%
summarise(maxc=mean(measurement)) %>%
left_join(bin_info, by="bin") %>%
as.data.frame()
ggplot(maxc, aes(mid, maxc))+geom_point()+coord_trans(x="log10")
ggplot(maxc[-c(1:3, 7, 10),], aes(mid, maxc))+geom_point()+coord_trans(x="log10")
#Try a smoothing spline
maxc_log <- maxc[-c(1:3, 7, 10),] %>%
mutate(mid_log=log10(mid))
ss <- smooth.spline(x=as.matrix(select(maxc_log, mid_log, maxc)), lambda=0.0001)
plot_ss <- function(x) predict(ss, x)$y
plot(maxc~mid_log, data=maxc_log, col="red")
curve(plot_ss, from=min(log10(maxc$lower)), to=max(log10(maxc$upper)), add=TRUE)
abline(v=log10(165))
maxc <- maxc %>%
mutate(predc=plot_ss(log10(mid)), k=k) %>%
mutate(predc=ifelse(predc<0, 0, predc), k=ifelse(k<0, 0, k))
maxc
size_class %>% mutate(k=ws/0.4)
